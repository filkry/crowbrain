{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import scipy as sp\n",
      "import numpy as np\n",
      "import csv, os\n",
      "import re\n",
      "import scipy.stats as stats\n",
      "import networkx as nx\n",
      "import cPickle as pickle\n",
      "import itertools\n",
      "\n",
      "from collections import defaultdict, OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "\n",
      "The plan is to read in a bunch of fields from our various data sources and then do some stats on them.\n",
      "\n",
      "Note that the first four fields together provide a unique way of identifying the answer (this could be better).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_data_dirs = [\n",
      "                  '/processed_data/pilot18',\n",
      "                  '/processed_data/pilot17',\n",
      "                  '/processed_data/pilot16',\n",
      "                  '/processed_data/pilot14',\n",
      "                  '/processed_data/pilot13',\n",
      "                  '/processed_data/pilot12',\n",
      "                  '/processed_data/pilot11',]\n",
      "\n",
      "manual_csvs = map(lambda x: '/processed_data/pilot18_metrics/' + x + '-scores.csv',\n",
      "                         ['fil', 'mike'])\n",
      "\n",
      "def metrics_folder(x):\n",
      "    return '/processed_data/pilot18_metrics/' + x\n",
      "\n",
      "idea_cluster_csvs = {qc: metrics_folder(\"_%s.csv\" % qc) for qc in \\\n",
      "                     ['iPod', 'turk']}\n",
      "                     #['charity', 'iPod', 'forgot_name', 'turk']}\n",
      "cluster_tree_csvs = {qc: metrics_folder(\"_%s_clusters.csv\" % qc) for qc in \\\n",
      "                     ['iPod', 'turk']}\n",
      "                     #['charity', 'iPod', 'forgot_name', 'turk']}\n",
      "    \n",
      "df_output_csv = '/processed_data/pilot18_notebook_output/instances.csv'\n",
      "rmdf_output_csv = '/processed_data/pilot18_notebook_output/runs.csv'\n",
      "clustersdf_output_csv = '/processed_data/pilot18_notebook_output/cluster_trees.csv'\n",
      "\n",
      "# Read in a bunch of base data\n",
      "\n",
      "def read_files(fils):\n",
      "    rows = []\n",
      "    for f in fils:\n",
      "        rows = rows + read_file(f)\n",
      "    return rows\n",
      "\n",
      "def read_base_data(dirs):\n",
      "    rows = []\n",
      "    for d in dirs:\n",
      "      for f in os.listdir(d):\n",
      "        full_name = os.path.join(d,f)\n",
      "        if os.path.isdir(full_name):\n",
      "            print \"I deleted the code here\"\n",
      "        else:\n",
      "          if f == 'answers.csv':\n",
      "            rows = rows + read_file(full_name)\n",
      "    return rows\n",
      "\n",
      "def read_file(f):\n",
      "    with open(f) as fin:\n",
      "        l = fin.readline()\n",
      "        # If we see the follow, it's an early run we can ignore\n",
      "        if 'Number of Answers' in l:\n",
      "            return\n",
      "        fin.seek(0)\n",
      "        sep = '|'\n",
      "        # Guess separator character\n",
      "        if l.count(',') > l.count('|'):\n",
      "            sep = ','\n",
      "            \n",
      "        # Just cache for now\n",
      "        rows = []\n",
      "        for row in csv.reader(fin, delimiter=sep):\n",
      "            if 'hashed_worker_id' in row or 'worker_id' in row or 'cluster_parent' in row:\n",
      "                continue\n",
      "            rows.append(row + [f])\n",
      "            \n",
      "        return rows\n",
      "\n",
      "def clean_missing(v):\n",
      "    return 0 if v == '' or v == 'missing' else v\n",
      "\n",
      "def series_from_row(rows, index, t):      \n",
      "    if t == object:\n",
      "        return pd.Series([row[index] for row in rows], dtype=t)\n",
      "    elif t == datetime64:\n",
      "        return pd.Series([np.datetime64(row[index]) for row in rows], dtype=t)\n",
      "    else:\n",
      "        s = pd.Series([clean_missing(row[index]) for row in rows], dtype=t)\n",
      "        return s\n",
      "\n",
      "merge_column_names = ['worker_id', 'question_code', 'answer_num', 'num_requested']\n",
      "    \n",
      "# Read in the main processed data files\n",
      "all_rows = read_base_data(base_data_dirs)\n",
      "num_responses = len(all_rows)\n",
      "\n",
      "bad_times = [(0 if (r[9] == 'missing' or r[10] == 'missing' or \\\n",
      "                    int(r[9]) <=0 or int(r[10]) <= 0) else 1) for r in all_rows]\n",
      "\n",
      "df_base = pd.DataFrame({'worker_id': pd.Series([row[0] for row in all_rows], dtype=object),\n",
      "            'question_code': pd.Series([row[2] for row in all_rows], dtype=object),\n",
      "            'num_requested': pd.Series([row[5] for row in all_rows], dtype=uint8),\n",
      "            'answer_num': pd.Series([row[6] for row in all_rows], dtype=uint8),\n",
      "            'answer': pd.Series([row[7] for row in all_rows], dtype=object),\n",
      "            'word_count': pd.Series([row[8] for row in all_rows], dtype=uint32),\n",
      "            'submit_datetime': pd.Series(pd.to_datetime([row[12] for row in all_rows])),\n",
      "            'accept_datetime': pd.Series(pd.to_datetime([row[13] for row in all_rows])),\n",
      "            'start_time': series_from_row(all_rows, 9, uint64),\n",
      "            'end_time': series_from_row(all_rows, 10, uint64),\n",
      "            'valid_time': pd.Series(bad_times, dtype=uint8),\n",
      "            'batch_file': series_from_row(all_rows, 14, object),\n",
      "})\n",
      "\n",
      "print len(df_base)\n",
      "\n",
      "## Dropping unlimited condition\n",
      "print \"With unlimited\", len(df_base)\n",
      "\n",
      "#print \"iPod unlimited\"\n",
      "#ipodf = df_base[df_base['question_code']=='iPod']\n",
      "#print \"num instances\", len(ipodf)\n",
      "\n",
      "#groups = ipodf.groupby(['worker_id', 'submit_datetime'])\n",
      "#print \"num hits\", len(groups)\n",
      "\n",
      "#print \"num workers\", len(set(ipodf['worker_id']))\n",
      "\n",
      "\n",
      "df_base = df_base[~(df_base['num_requested'] == 0)]\n",
      "print \"Without unlimited\", len(df_base)\n",
      "\n",
      "# Check for repeat workers\n",
      "is_repeat = pd.Series([0 for i in df_base.index], index=df_base.index)\n",
      "df_base = df_base.sort(['submit_datetime'])\n",
      "runs = df_base.groupby(['worker_id', 'question_code', 'num_requested', 'submit_datetime'])\n",
      "\n",
      "last_sdt = None\n",
      "seen_keys = set()\n",
      "\n",
      "for (wid, qc, nr, sdt), run in runs:\n",
      "    assert (last_sdt is None or sdt >= last_sdt)\n",
      "    assert (nr >= len(run))\n",
      "    if (wid, qc) in seen_keys:\n",
      "        for i in run.index:\n",
      "            is_repeat[i] = 1\n",
      "    else:\n",
      "        seen_keys.add((wid, qc))\n",
      "            \n",
      "df_base['is_repeat_worker'] = is_repeat\n",
      "\n",
      "\n",
      "# Read in heirarchical clusters\n",
      "rows = [r for key in idea_cluster_csvs\n",
      "          for r in read_file(idea_cluster_csvs[key])]\n",
      "print len(rows)\n",
      "df = pd.merge(df_base,\n",
      "              pd.DataFrame({'worker_id': series_from_row(rows, 5, object),\n",
      "                  'question_code': series_from_row(rows, 0, object),\n",
      "                  'num_requested': series_from_row(rows, 7, uint8),\n",
      "                  'answer_num': series_from_row(rows, 4, uint8),\n",
      "                  'idea': series_from_row(rows, 2, uint64),\n",
      "                  'answer': series_from_row(rows, 3, object),\n",
      "                  'valid_cluster': pd.Series([1 for row in rows], dtype=uint8),}),\n",
      "              'left', merge_column_names + ['answer'])\n",
      "\n",
      "print \"After clusters:\", len(df)\n",
      "\n",
      "# Read in manual codes\n",
      "\n",
      "def read_manual_csv(name):\n",
      "    index = 0 if name == 'fil' else 1\n",
      "    rows = read_file(manual_csvs[index])\n",
      "    \n",
      "    df = pd.DataFrame({'worker_id': series_from_row(rows, 0, object),\n",
      "            'question_code': series_from_row(rows, 2, object),\n",
      "            'num_requested': series_from_row(rows, 5, uint8),\n",
      "            'answer_num': series_from_row(rows, 6, uint8),\n",
      "            ('utility_%s' % name): series_from_row(rows, 13, uint8),\n",
      "            ('realistic_%s' % name): series_from_row(rows, 14, uint8),\n",
      "            ('distance_%s' % name): series_from_row(rows, 16, uint8),\n",
      "            ('valid_%s' % name): pd.Series([1 for row in rows], dtype=uint8),\n",
      "    })\n",
      "    return df\n",
      "\n",
      "df = pd.merge(df, read_manual_csv('mike'), 'left', merge_column_names)\n",
      "df = pd.merge(df, read_manual_csv('fil'), 'left', merge_column_names)\n",
      "\n",
      "print len(df)\n",
      "\n",
      "df_repeat = df.copy()\n",
      "\n",
      "df = df[df['is_repeat_worker'] == 0]\n",
      "print len(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10322\n",
        "With unlimited 10322\n",
        "Without unlimited 10028\n",
        "5699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "After clusters: 10028\n",
        "10028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9286\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nr_conds = list(set(df['num_requested']))\n",
      "nr_conds = sorted(nr_conds)\n",
      "print nr_conds\n",
      "\n",
      "qc_conds = list(set(df['question_code']))\n",
      "print qc_conds\n",
      "\n",
      "matplotlib_colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
      "\n",
      "qc_colors = {None: matplotlib_colors[0]}\n",
      "for i, code in enumerate(qc_conds):\n",
      "    qc_colors[code] = matplotlib_colors[i+1]\n",
      "print qc_colors\n",
      "\n",
      "nr_colors = {None: matplotlib_colors[0]}\n",
      "for i, nr in enumerate(nr_conds):\n",
      "    nr_colors[nr] = matplotlib_colors[i+1]\n",
      "print nr_colors\n",
      "\n",
      "cond_colors = {'question_code': qc_colors,\n",
      "                'num_requested': nr_colors }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[5, 10, 20, 50, 75, 100]\n",
        "['iPod', 'turk', 'forgot_name', 'charity']\n",
        "{None: 'b', 'turk': 'r', 'iPod': 'g', 'forgot_name': 'c', 'charity': 'm'}\n",
        "{100: 'k', 5: 'g', None: 'b', 75: 'y', 50: 'm', 20: 'c', 10: 'r'}\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Generate cluster trees and tree metrics\n",
      "\n",
      "Note: all of this is being cached for convenience, and assumes the tree structure is static!\n",
      "\n",
      "+ cluster o_score"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dumb_strip(s):\n",
      "    return ''.join([c for c in s if c in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\\\n",
      "    abcdefghijklmnopqrstuvwxyz1234567890 \"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_depth(forest, node):\n",
      "    parents = forest.predecessors(node)\n",
      "    if parents:\n",
      "        p = parents[0]\n",
      "        if 'depth' not in forest.node[p]:\n",
      "            gen_depth(forest, p)\n",
      "        forest.node[node]['depth'] = forest.node[p]['depth'] + 1\n",
      "    else:\n",
      "        forest.node[node]['depth'] = 0\n",
      "    \n",
      "    smd = forest.graph['subtree_max_depth']\n",
      "    root = forest.node[node]['subtree_root']\n",
      "    smd[root] = max(smd[root], forest.node[node]['depth'])\n",
      "\n",
      "def all_nodes_under(forest, node):\n",
      "    ret = [node]\n",
      "    for s in forest.successors(node):\n",
      "        ret += all_nodes_under(forest, s)\n",
      "    return ret\n",
      "\n",
      "def cluster_forest(structure_csv):\n",
      "    f = nx.DiGraph()\n",
      "    f.graph['subtree_roots'] = set()\n",
      "    f.graph['subtree_max_depth'] = defaultdict(int)\n",
      "    \n",
      "    rows = read_file(structure_csv)\n",
      "        \n",
      "    if len(rows) == 0:\n",
      "        return f\n",
      "    \n",
      "    for qc, child, parent, label, fn in rows:\n",
      "        c = int(child)\n",
      "        p = int(parent)\n",
      "        if parent != '':\n",
      "            f.add_edge(p, c)\n",
      "        else:\n",
      "            f.add_node(c)\n",
      "        f.node[c]['label'] = dumb_strip(label) if len(label) > 0 else None\n",
      "            \n",
      "    # delete the single root node\n",
      "    root = nx.topological_sort(f)[0]\n",
      "    f.remove_nodes_from([root])\n",
      "    \n",
      "    for node in f.nodes():        \n",
      "        # Subtree root\n",
      "        cur = node\n",
      "        while(len(f.predecessors(cur)) > 0):\n",
      "            cur = f.predecessors(cur)[0]\n",
      "        f.node[node]['subtree_root'] = cur\n",
      "        f.graph['subtree_roots'].add(cur)\n",
      "        \n",
      "        # descendents\n",
      "        f.node[node]['all_nodes_under'] = all_nodes_under(f, node)\n",
      "        \n",
      "    # depth\n",
      "    for node in f.nodes():\n",
      "        if 'depth' not in f.node[node]:\n",
      "            gen_depth(f, node)\n",
      "            \n",
      "    # height\n",
      "    for n in f.nodes():\n",
      "        smd = f.graph['subtree_max_depth']\n",
      "        root = f.node[n]['subtree_root']\n",
      "        f.node[n]['height'] = smd[root] - f.node[n]['depth']\n",
      "        \n",
      "    # remix_targets\n",
      "    for n in f.nodes():\n",
      "        targets = set([n])\n",
      "        \n",
      "        # all parents\n",
      "        cur = n\n",
      "        while len(f.predecessors(cur)) > 0:\n",
      "            cur = f.predecessors(cur)[0]\n",
      "            targets.add(cur)\n",
      "        \n",
      "        # all siblings\n",
      "        for p in f.predecessors(n):\n",
      "            for s in f.successors(p):\n",
      "                targets.add(s)\n",
      "        \n",
      "        # all children\n",
      "        targets = targets.union(set(f.node[n][\"all_nodes_under\"]))\n",
      "        \n",
      "        f.node[n]['remix_of'] = targets\n",
      "        \n",
      "    return f\n",
      "\n",
      "cluster_forests = {qc: cluster_forest(cluster_tree_csvs[qc]) for qc in cluster_tree_csvs.keys()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Put cluster metrics in their own dataframe\n",
      "\n",
      "TODO: I can't remember why this is so verbose"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def num_instances_in(df, clusters):\n",
      "    return sum(len(df[df['idea'] == c]) for c in clusters)\n",
      "\n",
      "ids = []\n",
      "labels = []\n",
      "is_roots = []\n",
      "is_leafs = []\n",
      "roots = []\n",
      "num_nodes_under = []\n",
      "subtree_probabilitys = []\n",
      "depths = []\n",
      "heights = []\n",
      "qcs = []\n",
      "num_childrens = []\n",
      "num_instances_under = []\n",
      "subtree_probability = []\n",
      "idea_probability = []\n",
      "num_instances = []\n",
      "num_workers = []\n",
      "num_ideas = []\n",
      "parents = []\n",
      "\n",
      "print qc_conds\n",
      "\n",
      "for qc in qc_conds:\n",
      "    sub_df = df[df['question_code'] == qc]\n",
      "    print len(sub_df)\n",
      "    print sum(sub_df['is_repeat_worker'])\n",
      "    \n",
      "    if qc not in cluster_forests:\n",
      "        print \"Skipping\", qc\n",
      "        continue\n",
      "    \n",
      "    f = cluster_forests[qc]\n",
      "    for n in f.nodes():\n",
      "        nd = f.node[n]\n",
      "        \n",
      "        idea = n\n",
      "        \n",
      "        ids.append(n)\n",
      "        if len(f.predecessors(n)) > 0:\n",
      "            parents.append(f.predecessors(n)[0])\n",
      "        else:\n",
      "            parents.append(-1)\n",
      "        labels.append(nd['label'])\n",
      "        is_roots.append(n == nd['subtree_root'])\n",
      "        is_leafs.append(len(f.successors(n)) == 0)\n",
      "        num_childrens.append(len(f.successors(n)))\n",
      "        roots.append(nd['subtree_root'])\n",
      "\n",
      "        depths.append(nd['depth'])\n",
      "        heights.append(nd['height'])\n",
      "        qcs.append(qc)\n",
      "        num_nodes_under.append(len(nd['all_nodes_under']))\n",
      "        \n",
      "        # Metrics for entire dataset; see time-based below\n",
      "        num_instances_under.append(num_instances_in(sub_df, all_nodes_under(f, idea)))\n",
      "        \n",
      "        root_idea = f.node[idea]['subtree_root']\n",
      "        nus = num_instances_in(sub_df, all_nodes_under(f, root_idea))\n",
      "        subtree_probability.append(float(nus) / len(sub_df))\n",
      "        \n",
      "        nii = num_instances_in(sub_df,[idea])\n",
      "        idea_probability.append(float(nii) / len(sub_df))\n",
      "        num_ideas.append(nii)\n",
      "        \n",
      "        instance_df = sub_df[sub_df['idea'] == idea]\n",
      "        num_instances.append(len(instance_df))\n",
      "        num_workers.append(len(set(instance_df['worker_id'])))\n",
      "\n",
      "print len(ids), len(roots)\n",
      "        \n",
      "clusters_df = pd.DataFrame({\n",
      "        'idea': pd.Series(ids, dtype=uint64),\n",
      "        'parent': pd.Series(parents, dtype=int64),\n",
      "        'idea_label': pd.Series(labels, dtype=object),\n",
      "        'is_root': pd.Series(is_roots, dtype=uint8),\n",
      "        'is_leaf': pd.Series(is_leafs, dtype=uint8),\n",
      "        'subtree_root': pd.Series(roots, dtype=uint64),\n",
      "        'depth_in_subtree': pd.Series(depths, dtype=uint32),\n",
      "        'height_in_subtree': pd.Series(heights, dtype=uint32),\n",
      "        'question_code': pd.Series(qcs, dtype=object),\n",
      "        'num_nodes_under': pd.Series(num_nodes_under, dtype=uint64),\n",
      "        'num_children': pd.Series(num_childrens, dtype=uint64),\n",
      "        'num_instances_under': pd.Series(num_instances_under, dtype=uint64),\n",
      "        'subtree_probability': pd.Series(subtree_probability, dtype=float64),\n",
      "        'idea_probability': pd.Series(idea_probability, dtype=float64),\n",
      "        'num_instances': pd.Series(num_instances, dtype=uint64),\n",
      "        'num_workers': pd.Series(num_workers, dtype=uint64),\n",
      "        'num_ideas_under': pd.Series(num_ideas, dtype=uint64),\n",
      "    })\n",
      "\n",
      "clusters_df['subtree_oscore'] = 1 - clusters_df['subtree_probability']\n",
      "clusters_df['idea_oscore'] = 1 - clusters_df['idea_probability']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['iPod', 'turk', 'forgot_name', 'charity']\n",
        "3007\n",
        "0\n",
        "2075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "2267"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "Skipping forgot_name\n",
        "1937\n",
        "0\n",
        "Skipping charity\n",
        "2486 2486\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Merge idea dataframe with cluster dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Pre cluster merge data size:\", len(df)\n",
      "df = pd.merge(df, clusters_df, 'left', ['idea', 'question_code'])\n",
      "print \"Post cluster merge data size:\", len(df)\n",
      "\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pre cluster merge data size: 9286\n",
        "Post cluster merge data size: 9286\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 9286 entries, 0 to 9285\n",
        "Data columns (total 40 columns):\n",
        "accept_datetime        9286  non-null values\n",
        "answer                 9286  non-null values\n",
        "answer_num             9286  non-null values\n",
        "batch_file             9286  non-null values\n",
        "end_time               9286  non-null values\n",
        "num_requested          9286  non-null values\n",
        "question_code          9286  non-null values\n",
        "start_time             9286  non-null values\n",
        "submit_datetime        9286  non-null values\n",
        "valid_time             9286  non-null values\n",
        "word_count             9286  non-null values\n",
        "worker_id              9286  non-null values\n",
        "is_repeat_worker       9286  non-null values\n",
        "idea                   5082  non-null values\n",
        "valid_cluster          5082  non-null values\n",
        "distance_mike          1103  non-null values\n",
        "realistic_mike         1103  non-null values\n",
        "utility_mike           1103  non-null values\n",
        "valid_mike             1103  non-null values\n",
        "distance_fil           1103  non-null values\n",
        "realistic_fil          1103  non-null values\n",
        "utility_fil            1103  non-null values\n",
        "valid_fil              1103  non-null values\n",
        "depth_in_subtree       5082  non-null values\n",
        "height_in_subtree      5082  non-null values\n",
        "idea_label             3645  non-null values\n",
        "idea_probability       5082  non-null values\n",
        "is_leaf                5082  non-null values\n",
        "is_root                5082  non-null values\n",
        "num_children           5082  non-null values\n",
        "num_ideas_under        5082  non-null values\n",
        "num_instances          5082  non-null values\n",
        "num_instances_under    5082  non-null values\n",
        "num_nodes_under        5082  non-null values\n",
        "num_workers            5082  non-null values\n",
        "parent                 5082  non-null values\n",
        "subtree_probability    5082  non-null values\n",
        "subtree_root           5082  non-null values\n",
        "subtree_oscore         5082  non-null values\n",
        "idea_oscore            5082  non-null values\n",
        "dtypes: datetime64[ns](2), float64(26), int64(1), object(7), uint32(1), uint8(3)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Generate some extra columns of metrics\n",
      "\n",
      "+ time_spent\n",
      "+ accept_to_submit_timedelta"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['time_spent'] = df['end_time'] - df['start_time']\n",
      "\n",
      "sub_df = df[(df['valid_time'] > 0)]\n",
      "assert(min(sub_df['time_spent']) > 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Outmix/inmix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_mixing(clustered_df):\n",
      "    dist = pd.Series([None for i in df.index], index=df.index)\n",
      "    dist_im = pd.Series([None for i in df.index], index=df.index)\n",
      "    im = pd.Series([0 for i in df.index], index=df.index)\n",
      "    mm = pd.Series([0 for i in df.index], index=df.index)\n",
      "    om = pd.Series([0 for i in df.index], index=df.index)\n",
      "    last_sim = pd.Series([None for i in df.index], index=df.index)\n",
      "    related_inmix = pd.Series([None for i in df.index], index=df.index)\n",
      "    \n",
      "    for (nr, wid, qc), run in clustered_df.groupby(['num_requested', 'worker_id', 'question_code']):\n",
      "        for ii, i in enumerate(run.index):\n",
      "            if ii == 0:\n",
      "                continue\n",
      "            for jj, j in reversed(list(enumerate(run.index[0:ii]))):\n",
      "                j_clus = run['idea'][j]\n",
      "                hcm_nc = cluster_forests[qc].node[j_clus]['remix_of']\n",
      "                if run['idea'][i] in hcm_nc:\n",
      "                    last_sim[i] = j\n",
      "                    dist[i] = ii - jj\n",
      "                    mm[j] = 1\n",
      "                    \n",
      "                    if om[j] > 0:\n",
      "                        dist_im[i] = dist[i] + dist_im[j]\n",
      "                        related_inmix[i] = related_inmix[j]\n",
      "                    else:\n",
      "                        im[j] = 1\n",
      "                        dist_im[i] = dist[i]\n",
      "                        related_inmix[i] = j\n",
      "                    \n",
      "                    om[i] = 1\n",
      "                    assert dist[i] > 0\n",
      "                    break\n",
      "    return dist, im, om, mm, dist_im, last_sim, related_inmix\n",
      "\n",
      "clustered_df = df[df['valid_cluster'] == 1]\n",
      "dist, im, om, mm, dist_im, last_sim, related_inmix = compute_mixing(clustered_df)\n",
      "\n",
      "df['distance_from_similar'] = dist\n",
      "df['is_inmix'] = im\n",
      "df['is_midmix'] = mm\n",
      "df['is_outmix'] = om\n",
      "df['distance_from_inmix'] = dist_im\n",
      "df['previous_similar_index'] = last_sim\n",
      "df['inmix_index'] = related_inmix\n",
      "\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 9286 entries, 0 to 9285\n",
        "Data columns (total 48 columns):\n",
        "accept_datetime           9286  non-null values\n",
        "answer                    9286  non-null values\n",
        "answer_num                9286  non-null values\n",
        "batch_file                9286  non-null values\n",
        "end_time                  9286  non-null values\n",
        "num_requested             9286  non-null values\n",
        "question_code             9286  non-null values\n",
        "start_time                9286  non-null values\n",
        "submit_datetime           9286  non-null values\n",
        "valid_time                9286  non-null values\n",
        "word_count                9286  non-null values\n",
        "worker_id                 9286  non-null values\n",
        "is_repeat_worker          9286  non-null values\n",
        "idea                      5082  non-null values\n",
        "valid_cluster             5082  non-null values\n",
        "distance_mike             1103  non-null values\n",
        "realistic_mike            1103  non-null values\n",
        "utility_mike              1103  non-null values\n",
        "valid_mike                1103  non-null values\n",
        "distance_fil              1103  non-null values\n",
        "realistic_fil             1103  non-null values\n",
        "utility_fil               1103  non-null values\n",
        "valid_fil                 1103  non-null values\n",
        "depth_in_subtree          5082  non-null values\n",
        "height_in_subtree         5082  non-null values\n",
        "idea_label                3645  non-null values\n",
        "idea_probability          5082  non-null values\n",
        "is_leaf                   5082  non-null values\n",
        "is_root                   5082  non-null values\n",
        "num_children              5082  non-null values\n",
        "num_ideas_under           5082  non-null values\n",
        "num_instances             5082  non-null values\n",
        "num_instances_under       5082  non-null values\n",
        "num_nodes_under           5082  non-null values\n",
        "num_workers               5082  non-null values\n",
        "parent                    5082  non-null values\n",
        "subtree_probability       5082  non-null values\n",
        "subtree_root              5082  non-null values\n",
        "subtree_oscore            5082  non-null values\n",
        "idea_oscore               5082  non-null values\n",
        "time_spent                9286  non-null values\n",
        "distance_from_similar     1865  non-null values\n",
        "is_inmix                  9286  non-null values\n",
        "is_midmix                 9286  non-null values\n",
        "is_outmix                 9286  non-null values\n",
        "distance_from_inmix       1865  non-null values\n",
        "previous_similar_index    1865  non-null values\n",
        "inmix_index               1865  non-null values\n",
        "dtypes: datetime64[ns](2), float64(26), int64(4), object(12), uint32(1), uint8(3)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Generate run-level metrics\n",
      "\n",
      "+ worker_idea\n",
      "+ question_code\n",
      "\n",
      "\n",
      "+ is_repeat_worker\n",
      "\n",
      "\n",
      "+ num_requested\n",
      "+ num_received\n",
      "\n",
      "+ num_unique_ideas\n",
      "\n",
      "+ accept_datetime\n",
      "+ submit_datetime\n",
      "\n",
      "\n",
      "+ mean_word_count"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_count(run, pass_func):\n",
      "    count = 0\n",
      "    for i in run.iterrows():\n",
      "        row = i[1]\n",
      "        if pass_func(row):\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "def run_mean(run, value_func):\n",
      "    t = 0.0\n",
      "    for i in run.iterrows():\n",
      "        row = i[1]\n",
      "        t += value_func(row)\n",
      "    return t / len(run)\n",
      "\n",
      "runs = df.groupby(['num_requested', 'worker_id', 'question_code', 'submit_datetime', 'accept_datetime'])\n",
      "\n",
      "wids = pd.Series([wid for ((nr, wid, qc, sdt, adt), run) in runs], dtype=object)\n",
      "qcs = pd.Series([qc for ((nr, wid, qc, sdt, adt), run) in runs], dtype=object)\n",
      "nrs = pd.Series([nr for ((nr, wid, qc, sdt, adt), run) in runs], dtype=float64) # make float for normalization purposes\n",
      "nrc = pd.Series([len(run) for (name, run) in runs], dtype=float64) # make float for normalization purposes\n",
      "\n",
      "# Assign run IDs to df\n",
      "rids = pd.Series([None for i in df.index], index=df.index)\n",
      "for i, (name, run) in enumerate(runs):\n",
      "    for j in run.index:\n",
      "        rids[j] = i\n",
      "df['run_id'] = rids\n",
      "\n",
      "# Test worked\n",
      "for i in nrc.index:\n",
      "    run_df = df[df['run_id'] == i]\n",
      "    assert(nrc[i] == len(run_df))\n",
      "        \n",
      "for i in nrs.index:\n",
      "    assert(nrs[i] >= nrc[i])\n",
      "\n",
      "adts = pd.Series(pd.to_datetime([adt for (nr, wid, qc, sdt, adt), run in runs]))\n",
      "sdts = pd.Series(pd.to_datetime([sdt for (nr, wid, qc, sdt, adt), run in runs]))\n",
      "\n",
      "mwc_val = lambda x: x['word_count']\n",
      "mwc = pd.Series([run_mean(run, mwc_val) for (name, run) in runs],\n",
      "                dtype=float64)\n",
      "\n",
      "nu = pd.Series([len(set(run['idea'])) for name, run in runs],\n",
      "                dtype=uint16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "irw_l = []\n",
      "seen = set()\n",
      "for (nr, wid, qc, sdt, adt), run in runs:\n",
      "    if run['is_repeat_worker'].iloc[0] == 1:\n",
      "        irw_l.append(1)\n",
      "    else:\n",
      "        irw_l.append(0)\n",
      "            \n",
      "irw = pd.Series(irw_l, dtype=uint8)\n",
      "\n",
      "print sum(irw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ num_unique_subtrees\n",
      "+ mean_subtree_oscore\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nus = pd.Series([len(set(run['subtree_root'])) for (name, run) in runs], dtype=uint16)\n",
      "\n",
      "mso_val = lambda x: x['subtree_oscore']\n",
      "mso = pd.Series([run_mean(run, mso_val) for (name, run) in runs], dtype=float64)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ num_inmix\n",
      "+ num_outmix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ni = pd.Series([sum(run['is_inmix']) for name, run in runs], dtype=float64)\n",
      "\n",
      "no = pd.Series([sum(run['is_outmix']) for name, run in runs], dtype=float64)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ valid_cluster\n",
      "+ valid_time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_test = lambda run: len(run) == len(run[(run['valid_cluster'] > 0)])\n",
      "cv = pd.Series([cv_test(run) for name, run in runs], dtype=uint8)\n",
      "\n",
      "tv_test = lambda run: len(run) == len(run[(run['valid_time'] > 0)])\n",
      "tv = pd.Series([tv_test(run) for name, run in runs], dtype=uint8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Drop redundant data from original dataframe\n",
      "df = df.drop('accept_datetime', 1)\n",
      "df = df.drop('submit_datetime', 1)\n",
      "df = df.drop('worker_id', 1)\n",
      "df = df.drop('num_requested', 1)\n",
      "df = df.drop('question_code', 1)\n",
      "\n",
      "rmdf = pd.DataFrame({'worker_id': wids,\n",
      "                            'question_code': qcs,\n",
      "                            'num_requested': nrs,\n",
      "                            'num_received': nrc,\n",
      "                            'accept_datetime': adts,\n",
      "                            'submit_datetime': sdts,\n",
      "                            #'is_repeat_worker': irw,\n",
      "                            'r_mean_word_count': mwc,\n",
      "                            'r_num_unique_ideas': nu,\n",
      "                            'r_num_unique_subtrees': nus,\n",
      "                            #'mean_subtree_oscore': mhclo,# Think about where I use this; is it better to just take from all ideas?\n",
      "                            'num_inmix': ni, # same as above\n",
      "                            'num_outmix': no, # same as above\n",
      "                            'r_valid_cluster': cv,\n",
      "                            'r_valid_time': tv,\n",
      "                            })\n",
      "\n",
      "# assert(len(runs) == len(run_metrics_df)) # weird memory error\n",
      "\n",
      "df = df.merge(rmdf, right_index=True, left_on=['run_id'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Final DF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df\n",
      "df.to_csv(df_output_csv)\n",
      "rmdf.to_csv(rmdf_output_csv)\n",
      "clusters_df.to_csv(clustersdf_output_csv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 9286 entries, 0 to 8556\n",
        "Data columns (total 57 columns):\n",
        "answer                    9286  non-null values\n",
        "answer_num                9286  non-null values\n",
        "batch_file                9286  non-null values\n",
        "end_time                  9286  non-null values\n",
        "start_time                9286  non-null values\n",
        "valid_time                9286  non-null values\n",
        "word_count                9286  non-null values\n",
        "is_repeat_worker          9286  non-null values\n",
        "idea                      5082  non-null values\n",
        "valid_cluster             5082  non-null values\n",
        "distance_mike             1103  non-null values\n",
        "realistic_mike            1103  non-null values\n",
        "utility_mike              1103  non-null values\n",
        "valid_mike                1103  non-null values\n",
        "distance_fil              1103  non-null values\n",
        "realistic_fil             1103  non-null values\n",
        "utility_fil               1103  non-null values\n",
        "valid_fil                 1103  non-null values\n",
        "depth_in_subtree          5082  non-null values\n",
        "height_in_subtree         5082  non-null values\n",
        "idea_label                3645  non-null values\n",
        "idea_probability          5082  non-null values\n",
        "is_leaf                   5082  non-null values\n",
        "is_root                   5082  non-null values\n",
        "num_children              5082  non-null values\n",
        "num_ideas_under           5082  non-null values\n",
        "num_instances             5082  non-null values\n",
        "num_instances_under       5082  non-null values\n",
        "num_nodes_under           5082  non-null values\n",
        "num_workers               5082  non-null values\n",
        "parent                    5082  non-null values\n",
        "subtree_probability       5082  non-null values\n",
        "subtree_root              5082  non-null values\n",
        "subtree_oscore            5082  non-null values\n",
        "idea_oscore               5082  non-null values\n",
        "time_spent                9286  non-null values\n",
        "distance_from_similar     1865  non-null values\n",
        "is_inmix                  9286  non-null values\n",
        "is_midmix                 9286  non-null values\n",
        "is_outmix                 9286  non-null values\n",
        "distance_from_inmix       1865  non-null values\n",
        "previous_similar_index    1865  non-null values\n",
        "inmix_index               1865  non-null values\n",
        "run_id                    9286  non-null values\n",
        "accept_datetime           9286  non-null values\n",
        "num_inmix                 9286  non-null values\n",
        "num_outmix                9286  non-null values\n",
        "num_received              9286  non-null values\n",
        "num_requested             9286  non-null values\n",
        "question_code             9286  non-null values\n",
        "r_mean_word_count         9286  non-null values\n",
        "r_num_unique_ideas        9286  non-null values\n",
        "r_num_unique_subtrees     9286  non-null values\n",
        "r_valid_cluster           9286  non-null values\n",
        "r_valid_time              9286  non-null values\n",
        "submit_datetime           9286  non-null values\n",
        "worker_id                 9286  non-null values\n",
        "dtypes: datetime64[ns](2), float64(31), int64(4), object(13), uint16(2), uint32(1), uint8(4)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mass of Ideas/Categories over time\n",
      "\n",
      "Generates an html file that shows all responses color-coded and adds them as a slider moves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import colorsys\n",
      "import math\n",
      "from jinja2 import Environment, FileSystemLoader\n",
      "from collections import Counter\n",
      "\n",
      "def hsv_to_html(h, s, v):\n",
      "    r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
      "    return \"#%02x%02x%02x\" % (math.floor(r * 255),\n",
      "                             math.floor(g * 255),\n",
      "                             math.floor(b * 255))\n",
      "\n",
      "def gen_color_set(xs):\n",
      "    return { x: hsv_to_html(ix * 1.0 / len(xs), 0.75, 1.0)\n",
      "        for ix, x in enumerate(xs) }\n",
      "\n",
      "def gen_template_params(ois, colors):\n",
      "    \"\"\"\n",
      "    ois - ordered things\n",
      "    colors - dict of things to HTML colors\n",
      "    \"\"\"\n",
      "    \n",
      "    dicts = [{ 'time': 'time' + str(ix),\n",
      "               'color': colors[i] } for ix, i in enumerate(ois)]\n",
      "    c = Counter(d['color'] for d in dicts)\n",
      "    c_rank = [color for color, count in c.most_common()]\n",
      "    ideas = sorted(dicts, key= lambda d: c_rank.index(d['color']))\n",
      "    \n",
      "    return { 'ideas': ideas }\n",
      "\n",
      "env = Environment(loader=FileSystemLoader('templates'))\n",
      "template = env.get_template('idea_time_vis.html')\n",
      "\n",
      "tv = df[df['valid_time'] > 0]\n",
      "for qc in cluster_forests.keys():\n",
      "    sub_df = tv[tv['question_code'] == qc].sort('end_time')\n",
      "    ideas = set(sub_df['idea'])\n",
      "    idea_colors = gen_color_set(ideas)\n",
      "    \n",
      "    html = template.render(gen_template_params(sub_df['idea'], idea_colors))\n",
      "    with open('ipython_output/idea_time_vis_%s.html' % qc, 'w') as f:\n",
      "        f.write(html)\n",
      "        \n",
      "for qc in cluster_forests.keys():\n",
      "    sub_df = tv[tv['question_code'] == qc].sort('end_time')\n",
      "    cats = set(sub_df['subtree_root'])\n",
      "    cat_colors = gen_color_set(cats)\n",
      "    \n",
      "    html = template.render(gen_template_params(sub_df['subtree_root'],\n",
      "                                               cat_colors))\n",
      "    with open('ipython_output/idea_time_vis_%s_cats.html' % qc, 'w') as f:\n",
      "        f.write(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}